{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# **Analysis Phase**\n",
    "---\n",
    "\n",
    "The analysis phase is the first step in the Soundlight processing chain. It is in charge of loading the song, extracting all relevant artifacts and saving the results.\n",
    "\n",
    "It is composed of the following tasks:\n",
    "\n",
    "## 1. Audio Input \n",
    "In this task, the audio is loaded in the program. The file metadata is read and, if needed, converted to the appropriate format.\n",
    "Also, the audio levels might be normalized and other preprocessing steps are taken, if necessary.\n",
    "\n",
    "This task employs [ffmpeg][11] to convert audio between codecs and [tinytag][12] to read the file's metadata.\n",
    "\n",
    "[ffmpeg][11] needs to be installed in the host system. If running on Windows, use `winget install ffmpeg`.\n",
    "[tinytag][12] is installed via `pip` with `pip install tinytag`.\n",
    "\n",
    "## 2. Beat and Key recognition  \n",
    "In this task, a basic analysis of key, BPM and beat offset are performed, which constitutes the base of the song profile.\n",
    "\n",
    "\n",
    "## 3. Phrase Analysis  \n",
    "In this task, the musical phrases of the song are extracted and recorded from the source. This increments the coherence of the generation, as it provides valuable structural data for future steps.\n",
    "\n",
    "This task employs the methods provided by [All-in-One][31] to perform its analysis.\n",
    "\n",
    "\n",
    "## 4. Stemming (Source Separation)  \n",
    "In this task, the source song is separated into stems (vocals, melody, drums and other). This task is important because it allows the different parts of the song to be treated separately, giving way to advanced generation that would otherwise be impossible. It is also decided here if each stem contains valuable information, and if not, it is discarded.\n",
    "\n",
    "\n",
    "## 5. Stem Pulse and Frequency mapping  \n",
    "In this task, stems are analyzed separately for sound pulses. From those, frequency and volume are extracted, and recorded individually for further use.\n",
    "\n",
    "\n",
    "## 6. Profile Construction  \n",
    "In this task, the results of all preceding tasks are incorporated into the song profile, which will be feeded to the next step's agents. This is important because it avoids having to reanalyze songs, by saving the results into a reusable format.\n",
    "\n",
    "\n",
    "## 7. Database Registration  \n",
    "In this task, the profile is optionally registered in a database for later library management.\n",
    "\n",
    "---\n",
    "\n",
    "<!--- Link references --->\n",
    "[11]: https://ffmpeg.org/\n",
    "[12]: https://github.com/tinytag/tinytag (GitHub: tinytag)\n",
    "[31]: https://github.com/mir-aidj/all-in-one (GitHub: All-in-One)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Audio Input\n",
    "The first task in analysis is the audio input, which starts by loading the song. It must be loaded inn binary mode, as the file is audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(path, \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to convert the file, we use `ffmpeg` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ffmpeg\n",
    "\n",
    "# From .mp3 to .wav, just change the extension. ffmpeg takes care of the rest\n",
    "ffmpeg.input(r\"U:\\TFG\\PoC\\resources\\CamelPhat, Yannis, Foals - Hypercolour.mp3\").output(r\"U:\\TFG\\PoC\\resources\\CamelPhat, Yannis, Foals - Hypercolour.wav\").run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Key and BPM Detection\n",
    "\n",
    "The key detection is done with help from `librosa`, which is one of the most used libraries when it comes to audio processing in Python.\n",
    "The code to detect the key is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install librosa\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Key: F#\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Load the audio file\n",
    "audio_file_path = r'U:\\TFG\\PoC\\resources\\CamelPhat, Yannis, Foals - Hypercolour.wav'\n",
    "y, sr = librosa.load(audio_file_path)\n",
    "\n",
    "# Compute the Chroma Short-Time Fourier Transform (chroma_stft)\n",
    "chromagram = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "\n",
    "# Calculate the mean chroma feature across time\n",
    "mean_chroma = np.mean(chromagram, axis=1)\n",
    "\n",
    "# Define the mapping of chroma features to keys\n",
    "chroma_to_key = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "\n",
    "# Find the key by selecting the maximum chroma feature\n",
    "estimated_key_index = np.argmax(mean_chroma)\n",
    "estimated_key = chroma_to_key[estimated_key_index]\n",
    "\n",
    "# Print the detected key\n",
    "print(\"Detected Key:\", estimated_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
